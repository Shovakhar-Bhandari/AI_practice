{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereâ€™s an expanded list of key components in Natural Language Processing (NLP) with brief explanations:\n",
    "\n",
    "### **1. Text Preprocessing**\n",
    "   - **Tokenization**: Divides text into smaller units such as words or sentences. This is a foundational step in text analysis.\n",
    "   - **Removing Stopwords**: Eliminates common words (like \"and,\" \"the,\" \"is\") that are not useful in the analysis as they do not carry significant meaning.\n",
    "   - **Stemming/Lemmatization**: Reduces words to their base or root form. Stemming often results in root forms that may not be actual words, while lemmatization maps words to their dictionary form. Eg : The root form of \"running\" is \"run.\"similarly : cleaning && cleaned to clean .\n",
    "\n",
    "### **2. Text Representation**\n",
    "   - **Bag of Words (BoW)**: Represents text as an unordered collection of words, disregarding grammar and word order but keeping track of word frequency.\n",
    "   - **TF-IDF (Term Frequency-Inverse Document Frequency)**: Weighs terms based on their frequency in a document relative to their occurrence across multiple documents, highlighting words that are more significant in specific contexts.\n",
    "   - **Word Embedding**: Represents words as dense vectors in continuous space, capturing semantic meanings and relationships. Examples include Word2Vec, GloVe, and FastText.\n",
    "\n",
    "### **3. Core NLP Tasks**\n",
    "   - **Sentiment Analysis**: Determines the sentiment behind a piece of text, categorizing it as positive, negative, or neutral.\n",
    "   - **Named Entity Recognition (NER)**: Identifies and classifies entities in text into predefined categories such as names of people, organizations, locations, dates, etc.\n",
    "   - **Machine Translation**: Automatically translates text from one language to another using techniques such as statistical models or neural networks.\n",
    "   - **Text Classification**: Assigns categories or labels to text based on its content. Examples include spam detection, topic categorization, etc.\n",
    "   - **Language Generation**: Involves generating coherent and contextually relevant text, such as in text completion, summarization, or chatbot responses.\n",
    "   - **Speech Recognition and Synthesis**: Converts spoken language into text (recognition) and vice versa (synthesis), enabling human-computer interaction through voice.\n",
    "\n",
    "### **4. Advanced NLP Techniques**\n",
    "   - **Contextualized Word Embeddings**: Models like BERT and GPT represent words in context, allowing for more nuanced understanding of language.\n",
    "   - **Sequence-to-Sequence Models**: Used in tasks like machine translation and summarization, where input and output are sequences of text.\n",
    "   - **Transformers**: A deep learning architecture that has revolutionized NLP by allowing for better handling of long-range dependencies and parallel processing.\n",
    "   - **Attention Mechanisms**: Focuses on specific parts of input when making predictions, improving the performance of models like Transformers.\n",
    "   - **Reinforcement Learning in NLP**: Used in tasks like dialogue systems and text generation, where the model learns through trial and error.\n",
    "\n",
    "This structured breakdown provides a comprehensive overview of the key components in NLP, highlighting both foundational techniques and advanced methodologies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
